{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 4\\SCI\\Challenge\\SP Project\\sp_project_janosh_marius\\backend_sp_db\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import datetime\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "exportdir = ['Imports', 'Exports', 'Database']\n",
    "\n",
    "notebook_dir = os.getcwd()  \n",
    "\n",
    "for exportdirs in exportdir:\n",
    "    parent_dir = os.path.dirname(notebook_dir)\n",
    "    output_dir = os.path.join(parent_dir, 'backend_sp_db', exportdirs)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x205a7216d40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS SP_Project\n",
    "             (ID INT PRIMARY KEY     NOT NULL);''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the database\n",
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "# List of months\n",
    "months = [\"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\", \"August\", \"September\", \"Oktober\", \"November\", \"Dezember\"]\n",
    "\n",
    "# Create an empty DataFrame to store the sums\n",
    "df_sum = pd.DataFrame(columns=['Month'])\n",
    "\n",
    "filter = \"DST OPS\"\n",
    "# Iterate over the months\n",
    "for month in months:\n",
    "    # Import data from Excel\n",
    "    df_cust = pd.read_excel(f\"Imports/{month}_21.xlsx\")\n",
    "\n",
    "    #Can be Used to filter Abteilung to DST IPS, DST NF or DST OP\n",
    "    df_cust = df_cust[df_cust[\"Abteilung (kurz)\"] == filter]  \n",
    "\n",
    "    # Calculate the sum of the values\n",
    "    total_sum_ÜS = round(df_cust['Saldo ÜS'].sum(), 2)\n",
    "    total_sum_GLAZ = round(df_cust['Saldo GLAZ'].sum(), 2)\n",
    "    total_sum_Covid = round(df_cust['Saldo Covid'].sum(), 2)\n",
    "    total_sum_Ist = round(df_cust['Ist'].sum(), 2)\n",
    "    total_sum_Soll = round(df_cust['Soll'].sum(),2)\n",
    "    total_sum_DIS = round(df_cust['Differenz Ist/Soll'].sum(),2)\n",
    "    total_sum_Ferien = round(df_cust['(5010) Ferien - Saldo'].sum(),2)\n",
    "\n",
    "    # Append the sum to the DataFrame\n",
    "    df_sum = df_sum.append({'Month': month, 'Saldo Überstunden': total_sum_ÜS, 'Saldo Glaz': total_sum_GLAZ, 'Saldo Covid': total_sum_Covid, 'Saldo IST': total_sum_Ist\n",
    "    , 'Saldo SOLL': total_sum_Soll,'Saldo DIS': total_sum_DIS, 'Saldo Ferien': total_sum_Ferien }, ignore_index=True)\n",
    "\n",
    "\n",
    "# Create a new table with the sums\n",
    "df_sum.to_sql(f\"SP_Project_Sums_{filter}\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "df_cust = pd.read_sql(\"\"\" SELECT\n",
    "                      SUM(Jan.[Saldo ÜS] + Feb.[Saldo ÜS]+ März.[Saldo ÜS]) FROM SP_Project_Januar AS Jan, SP_Project_Februar AS Feb, SP_Project_März AS März \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code: 401\n",
      "Error message: {\"message\":\"Bad credentials\",\"documentation_url\":\"https://docs.github.com/rest\"}\n",
      "           date ncumul_conf  ncumul_hosp\n",
      "309  2021-01-01       70233        445.0\n",
      "339  2021-01-31       82521        229.0\n",
      "367  2021-02-28       87545        126.0\n",
      "398  2021-03-31       95338        183.0\n",
      "428  2021-04-30      106775        210.0\n",
      "459  2021-05-31      111675         93.0\n",
      "489  2021-06-30      112897         21.0\n",
      "520  2021-07-31      116327         46.0\n",
      "551  2021-08-31      127460        192.0\n",
      "581  2021-09-30      139402        106.0\n",
      "612  2021-10-31      145236         67.0\n",
      "642  2021-11-30      168497        177.0\n",
      "673  2021-12-31      218717        171.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import sqlite3\n",
    "\n",
    "repo_owner = \"openZH\"\n",
    "\n",
    "repo_name = \"covid_19\"\n",
    "\n",
    "file_path = \"fallzahlen_kanton_total_csv/COVID19_Fallzahlen_Kanton_ZH_total.csv\"\n",
    "\n",
    "access_token = \"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\" \n",
    "\n",
    "# Set the API URL\n",
    "\n",
    "api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{file_path}\"\n",
    "\n",
    "headers = {}\n",
    "\n",
    "if access_token:\n",
    "\n",
    "    headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "\n",
    "# Send a GET request to the GitHub API\n",
    "\n",
    "response = requests.get(api_url, headers=headers)\n",
    "\n",
    "#Check the response status code\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Retrieve the download URL of the file\n",
    "\n",
    "    download_url = data[\"download_url\"]\n",
    "\n",
    "    # Send a GET request to the download URL\n",
    "\n",
    "    file_response = requests.get(download_url)\n",
    "\n",
    "    # Check the file response status code\n",
    "\n",
    "    if file_response.status_code == 200:\n",
    "\n",
    "    # Access and process the file content\n",
    "        file_content = file_response.text\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"File download failed with status code:\", file_response.status_code)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "    print(\"Error message:\", response.text)\n",
    "\n",
    "\n",
    "# Save the file_content as a temporary file\n",
    "with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "    temp_file.write(file_content.encode())\n",
    "    temp_file_name = temp_file.name\n",
    "\n",
    "# Read the temporary file as a DataFrame\n",
    "df = pd.read_csv(temp_file_name)\n",
    "\n",
    "selected_columns = ['date', 'ncumul_conf', 'ncumul_hosp', 'ncumul_ICU', 'ncumul_deceased']\n",
    "\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "df_selected['date'] = pd.to_datetime(df_selected['date']).dt.date \n",
    "\n",
    "targetdates = ['2021-01-01', '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30', \n",
    "               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31', '2021-09-30', \n",
    "               '2021-10-31', '2021-11-30', '2021-12-31']\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame(columns=selected_columns)\n",
    "\n",
    "# Iterate over the target dates and filter the DataFrame\n",
    "for targetdate in targetdates:\n",
    "    target_date = pd.to_datetime(targetdate)\n",
    "    df_filtered = df_selected[df_selected['date'] == target_date]\n",
    "\n",
    "\n",
    "    # Append the filtered DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df_filtered])\n",
    "\n",
    "# Print or use the combined DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Create a new DataFrame for the data to be inserted into the SQLite database\n",
    "df_covid = pd.DataFrame(columns=['date', 'cases', 'hospitalisation', 'ICU', 'deaths'])\n",
    "df_covid['date'] = combined_df['date']\n",
    "df_covid['cases'] = combined_df['ncumul_conf'].astype(int)  # Convert 'cases' column to integers\n",
    "df_covid['hospitalisation'] = combined_df['ncumul_hosp'].astype(int) \n",
    "df_covid['ICU'] = combined_df['ncumul_ICU'].astype(int) #\n",
    "df_covid['deaths'] = combined_df['ncumul_deceased'].astype(int) #\n",
    "\n",
    "# Establish a connection to the SQLite database\n",
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "# Insert the data into the \"Combined_Data\" table\n",
    "df_covid.to_sql(\"Covid_Data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
