{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\ZHAW\\Sc_Programming\\Project\\Github\\sp_project_janosh_marius\\backend_sp_db\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import datetime\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportdir = ['Imports', 'Exports', 'Database']\n",
    "\n",
    "\n",
    "for exportdirs in exportdir:\n",
    "    output_dir = os.path.join(r'C:\\ZHAW\\Sc_Programming\\Project\\Github\\sp_project_janosh_marius\\backend_sp_db', exportdirs, )\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"Database/project_SP.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x205a7216d40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('''CREATE TABLE IF NOT EXISTS SP_Project\n",
    "             (ID INT PRIMARY KEY     NOT NULL);''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the database\n",
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "# List of months\n",
    "months = [\"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\", \"August\", \"September\", \"Oktober\", \"November\", \"Dezember\"]\n",
    "\n",
    "# Create an empty DataFrame to store the sums\n",
    "df_sum = pd.DataFrame(columns=['Month'])\n",
    "\n",
    "\n",
    "# Iterate over the months\n",
    "for month in months:\n",
    "    # Import data from Excel\n",
    "    df_cust = pd.read_excel(f\"Imports/{month}_21.xlsx\")\n",
    "\n",
    "    #Can be Used to filter Abteilung to DST IPS, DST NF or DST OP\n",
    "    df_cust = df_cust[df_cust[\"Abteilung (kurz)\"] == \"DST OP\"]  \n",
    "\n",
    "    # Calculate the sum of the values\n",
    "    total_sum_ÜS = round(df_cust['Saldo ÜS'].sum(), 2)\n",
    "    total_sum_GLAZ = round(df_cust['Saldo GLAZ'].sum(), 2)\n",
    "    total_sum_Covid = round(df_cust['Saldo Covid'].sum(), 2)\n",
    "    total_sum_Ist = round(df_cust['Ist'].sum(), 2)\n",
    "    total_sum_Soll = round(df_cust['Soll'].sum(),2)\n",
    "    total_sum_DIS = round(df_cust['Differenz Ist/Soll'].sum(),2)\n",
    "    total_sum_Ferien = round(df_cust['(5010) Ferien - Saldo'].sum(),2)\n",
    "\n",
    "    # Append the sum to the DataFrame\n",
    "    df_sum = df_sum.append({'Month': month, 'Saldo Überstunden': total_sum_ÜS, 'Saldo Glaz': total_sum_GLAZ, 'Saldo Covid': total_sum_Covid, 'Saldo IST': total_sum_Ist\n",
    "    , 'Saldo SOLL': total_sum_Soll,'Saldo DIS': total_sum_DIS, 'Saldo Ferien': total_sum_Ferien }, ignore_index=True)\n",
    "\n",
    "\n",
    "# Create a new table with the sums\n",
    "df_sum.to_sql(\"SP_Project_Sums_OP\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  Total_ÜS  Total_GLAZ  Total_Covid  Total_Ist  Total_Soll  \\\n",
      "0      Januar   2005.19     1325.46         17.5   23916.20    23051.57   \n",
      "1     Februar   2000.16     1405.30         17.5   22617.66    23515.24   \n",
      "2        März   1904.49    -2720.37         15.5   26211.75    28983.94   \n",
      "3       April    225.11     2391.68         11.5   29176.58    26361.05   \n",
      "4         Mai    150.82     1203.77         11.5   29009.10    30148.22   \n",
      "5        Juni   1277.28      651.22         15.5   27102.16    29759.23   \n",
      "6        Juli   1180.05     -863.80         15.5   27241.33    29102.90   \n",
      "7      August   1110.24     -847.17         15.5   27902.49    28070.80   \n",
      "8   September   1061.68     -691.94         15.5   28552.18    28636.51   \n",
      "9     Oktober    210.43     1109.38         15.5   28783.09    27039.25   \n",
      "10   November    130.55     -260.46         15.5   26861.70    28310.65   \n",
      "11   Dezember    449.67     -683.82         15.5   26002.78    26517.81   \n",
      "\n",
      "    Total_DIS  Total_Ferien  \n",
      "0      864.68       3979.65  \n",
      "1     -897.64       4952.26  \n",
      "2    -2772.25       6811.04  \n",
      "3     2815.78       6235.90  \n",
      "4    -1139.25       6355.30  \n",
      "5    -2656.85       7099.79  \n",
      "6    -1861.40       5963.68  \n",
      "7     -168.31       4068.18  \n",
      "8      -84.50       3018.55  \n",
      "9     1743.84       2375.07  \n",
      "10   -1448.73       1732.69  \n",
      "11    -514.86       1385.65  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the database\n",
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "# Define the months list\n",
    "months = [\"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\", \"August\", \"September\", \"Oktober\", \"November\", \"Dezember\"]\n",
    "\n",
    "# Create an empty DataFrame to store the monthly totals\n",
    "monthly_totals = pd.DataFrame(columns=['Month', 'Total_ÜS', 'Total_GLAZ', 'Total_Covid', 'Total_Ist', 'Total_Soll', 'Total_DIS', 'Total_Ferien'])\n",
    "\n",
    "# Iterate over the months and perform calculations\n",
    "for month in months:\n",
    "    # Import data from Excel\n",
    "    df_cust = pd.read_excel(f\"Imports/{month}_21.xlsx\")\n",
    "\n",
    "    df_cust = df_cust[df_cust[\"Abteilung (kurz)\"] == \"DST IPS\"]\n",
    "\n",
    "    # Calculate the sum of the values\n",
    "    total_sum_ÜS = round(df_cust['Saldo ÜS'].sum(), 2)\n",
    "    total_sum_GLAZ = round(df_cust['Saldo GLAZ'].sum(), 2)\n",
    "    total_sum_Covid = round(df_cust['Saldo Covid'].sum(), 2)\n",
    "    total_sum_Ist = round(df_cust['Ist'].sum(), 2)\n",
    "    total_sum_Soll = round(df_cust['Soll'].sum(), 2)\n",
    "    total_sum_DIS = round(df_cust['Differenz Ist/Soll'].sum(), 2)\n",
    "    total_sum_Ferien = round(df_cust['(5010) Ferien - Saldo'].sum(), 2)\n",
    "    \n",
    "    # Append the monthly totals to the DataFrame\n",
    "    monthly_totals = monthly_totals.append({\n",
    "        'Month': month,\n",
    "        'Total_ÜS': total_sum_ÜS,\n",
    "        'Total_GLAZ': total_sum_GLAZ,\n",
    "        'Total_Covid': total_sum_Covid,\n",
    "        'Total_Ist': total_sum_Ist,\n",
    "        'Total_Soll': total_sum_Soll,\n",
    "        'Total_DIS': total_sum_DIS,\n",
    "        'Total_Ferien': total_sum_Ferien\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    df_sum = df_sum.append({'Month': month, 'Saldo Überstunden': total_sum_ÜS, 'Saldo Glaz': total_sum_GLAZ, 'Saldo Covid': total_sum_Covid, 'Saldo IST': total_sum_Ist\n",
    "    , 'Saldo SOLL': total_sum_Soll,'Saldo DIS': total_sum_DIS, 'Saldo Ferien': total_sum_Ferien }, ignore_index=True)\n",
    "\n",
    "\n",
    "# Create a new table with the sums\n",
    "df_sum.to_sql(\"SP_Project_Sums\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Print or use the monthly_totals DataFrame\n",
    "print(monthly_totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "df_cust = pd.read_sql(\"\"\" SELECT\n",
    "                      SUM(Jan.[Saldo ÜS] + Feb.[Saldo ÜS]+ März.[Saldo ÜS]) FROM SP_Project_Januar AS Jan, SP_Project_Februar AS Feb, SP_Project_März AS März  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code: 401\n",
      "Error message: {\"message\":\"Bad credentials\",\"documentation_url\":\"https://docs.github.com/rest\"}\n",
      "           date ncumul_conf  ncumul_hosp\n",
      "309  2021-01-01       70233        445.0\n",
      "339  2021-01-31       82521        229.0\n",
      "367  2021-02-28       87545        126.0\n",
      "398  2021-03-31       95338        183.0\n",
      "428  2021-04-30      106775        210.0\n",
      "459  2021-05-31      111675         93.0\n",
      "489  2021-06-30      112897         21.0\n",
      "520  2021-07-31      116327         46.0\n",
      "551  2021-08-31      127460        192.0\n",
      "581  2021-09-30      139402        106.0\n",
      "612  2021-10-31      145236         67.0\n",
      "642  2021-11-30      168497        177.0\n",
      "673  2021-12-31      218717        171.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Set the repository and file information\n",
    "\n",
    "repo_owner = \"openZH\"\n",
    "\n",
    "repo_name = \"covid_19\"\n",
    "\n",
    "file_path = \"fallzahlen_kanton_total_csv/COVID19_Fallzahlen_Kanton_ZH_total.csv\"\n",
    "\n",
    "access_token = \"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\" \n",
    "\n",
    "# Set the API endpoint URL\n",
    "\n",
    "api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{file_path}\"\n",
    "\n",
    "# Set the headers with an access token if required\n",
    "\n",
    "headers = {}\n",
    "\n",
    "if access_token:\n",
    "\n",
    "    headers[\"Authorization\"] = f\"Bearer {access_token}\"\n",
    "\n",
    "# Send a GET request to the GitHub API\n",
    "\n",
    "response = requests.get(api_url, headers=headers)\n",
    "\n",
    "#Check the response status code\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Retrieve the download URL of the file\n",
    "\n",
    "    download_url = data[\"download_url\"]\n",
    "\n",
    "    # Send a GET request to the download URL\n",
    "\n",
    "    file_response = requests.get(download_url)\n",
    "\n",
    "    # Check the file response status code\n",
    "\n",
    "    if file_response.status_code == 200:\n",
    "\n",
    "    # Access and process the file content\n",
    "        file_content = file_response.text\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"File download failed with status code:\", file_response.status_code)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "    print(\"Error message:\", response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the necessary code to retrieve the file_content\n",
    "\n",
    "# Save the file_content as a temporary file\n",
    "with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "    temp_file.write(file_content.encode())\n",
    "    temp_file_name = temp_file.name\n",
    "\n",
    "# Read the temporary file as a DataFrame\n",
    "df = pd.read_csv(temp_file_name)\n",
    "\n",
    "selected_columns = ['date', 'ncumul_conf', 'ncumul_hosp']\n",
    "\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "df_selected['date'] = pd.to_datetime(df_selected['date']).dt.date \n",
    "\n",
    "targetdates = ['2021-01-01', '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30', '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31', '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31']\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame(columns=selected_columns)\n",
    "\n",
    "# Iterate over the target dates and filter the DataFrame\n",
    "for targetdate in targetdates:\n",
    "    target_date = pd.to_datetime(targetdate)\n",
    "    df_filtered = df_selected[df_selected['date'] == target_date]\n",
    "\n",
    "\n",
    "    # Append the filtered DataFrame to the combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df_filtered])\n",
    "\n",
    "# Print or use the combined DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Create a new DataFrame for the data to be inserted into the SQLite database\n",
    "df_covid = pd.DataFrame(columns=['date', 'cases', 'hospitalisation'])\n",
    "df_covid['date'] = combined_df['date']\n",
    "df_covid['cases'] = combined_df['ncumul_conf'].astype(int)  # Convert 'cases' column to integers\n",
    "df_covid['hospitalisation'] = combined_df['ncumul_hosp'].astype(int)  #\n",
    "\n",
    "# Establish a connection to the SQLite database\n",
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "# Insert the data into the \"Combined_Data\" table\n",
    "df_covid.to_sql(\"Combined_Data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "Error binding parameter 0 - probably unsupported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m\"\u001b[39m\u001b[39mDatabase/project_SP.db\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df_covid\u001b[39m.\u001b[39;49mto_sql(\u001b[39m\"\u001b[39;49m\u001b[39mCombined_Data\u001b[39;49m\u001b[39m\"\u001b[39;49m, conn, if_exists\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Commit the changes to the database\u001b[39;00m\n\u001b[0;32m      6\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n",
      "File \u001b[1;32mc:\\Users\\spunk\\.conda\\envs\\spenv\\lib\\site-packages\\pandas\\core\\generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2987\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2988\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2989\u001b[0m     name,\n\u001b[0;32m   2990\u001b[0m     con,\n\u001b[0;32m   2991\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2992\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2993\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2994\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2995\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2996\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2997\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2998\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\spunk\\.conda\\envs\\spenv\\lib\\site-packages\\pandas\\io\\sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    692\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m     )\n\u001b[1;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mto_sql(\n\u001b[0;32m    696\u001b[0m     frame,\n\u001b[0;32m    697\u001b[0m     name,\n\u001b[0;32m    698\u001b[0m     if_exists\u001b[39m=\u001b[39mif_exists,\n\u001b[0;32m    699\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m    700\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m    701\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m    702\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    703\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    704\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m    706\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\spunk\\.conda\\envs\\spenv\\lib\\site-packages\\pandas\\io\\sql.py:2188\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, **kwargs)\u001b[0m\n\u001b[0;32m   2178\u001b[0m table \u001b[39m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2179\u001b[0m     name,\n\u001b[0;32m   2180\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2185\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   2186\u001b[0m )\n\u001b[0;32m   2187\u001b[0m table\u001b[39m.\u001b[39mcreate()\n\u001b[1;32m-> 2188\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize, method)\n",
      "File \u001b[1;32mc:\\Users\\spunk\\.conda\\envs\\spenv\\lib\\site-packages\\pandas\\io\\sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    945\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[1;32m--> 946\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[0;32m    947\u001b[0m \u001b[39m# GH 46891\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[1;32mc:\\Users\\spunk\\.conda\\envs\\spenv\\lib\\site-packages\\pandas\\io\\sql.py:1894\u001b[0m, in \u001b[0;36mSQLiteTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m   1892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_insert\u001b[39m(\u001b[39mself\u001b[39m, conn, keys, data_iter) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m   1893\u001b[0m     data_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_iter)\n\u001b[1;32m-> 1894\u001b[0m     conn\u001b[39m.\u001b[39;49mexecutemany(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minsert_statement(num_rows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), data_list)\n\u001b[0;32m   1895\u001b[0m     \u001b[39mreturn\u001b[39;00m conn\u001b[39m.\u001b[39mrowcount\n",
      "\u001b[1;31mInterfaceError\u001b[0m: Error binding parameter 0 - probably unsupported type."
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"Database/project_SP.db\")\n",
    "\n",
    "df_covid.to_sql(\"Combined_Data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
